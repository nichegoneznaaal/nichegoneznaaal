{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e48a22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e42e1ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_data_script(name_of_df): \n",
    "    total = name_of_df.isnull().sum().sort_values(ascending=False) \n",
    "    percent = (name_of_df.isnull().sum()/name_of_df.isnull().count()).sort_values(ascending=False) \n",
    "    missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent']) \n",
    "    return(missing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0579bfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gigachad = pd.read_csv('beeline_antispam_hakaton_id_samples.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8a68c188",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('time_key=2021-11-01.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c2a059a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46235, 3)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gigachad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b626ca24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ans = pd.read_csv('beeline_antispam_hakaton_id_samples.csv').dropna().drop('split',axis = 1)\n",
    "\n",
    "df_train =  df_train.merge(df_ans,left_on= 'id_a' ,right_on = 'id').drop(['id', 'start_time_local','time_key'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "715eb076",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a535a93c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_a</th>\n",
       "      <th>id_b</th>\n",
       "      <th>time_zone</th>\n",
       "      <th>duration</th>\n",
       "      <th>forward</th>\n",
       "      <th>zero_call_flg</th>\n",
       "      <th>source_b</th>\n",
       "      <th>source_f</th>\n",
       "      <th>num_b_length</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67596082</td>\n",
       "      <td>43588153</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67596082</td>\n",
       "      <td>82184937</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67596082</td>\n",
       "      <td>48927355</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67596082</td>\n",
       "      <td>10241386</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>67596082</td>\n",
       "      <td>229405</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id_a      id_b  time_zone  duration  forward  zero_call_flg  source_b  \\\n",
       "0  67596082  43588153          3         0        0              3         0   \n",
       "1  67596082  82184937          3         0        0              5         0   \n",
       "2  67596082  48927355          0         0        0              5         0   \n",
       "3  67596082  10241386          3         0        0              0         0   \n",
       "4  67596082    229405          0         0        1              5         1   \n",
       "\n",
       "   source_f  num_b_length  target  \n",
       "0         1            10     4.0  \n",
       "1         1            10     4.0  \n",
       "2         1            10     4.0  \n",
       "3         1            10     4.0  \n",
       "4         0            10     4.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ac77b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = xgb.XGBClassifier(max_depth=5, objective='multi:softmax', n_estimators=1000, \n",
    "                        num_classes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2b75df5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fae7a163",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df_train.drop(['target'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10be4568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_a</th>\n",
       "      <th>id_b</th>\n",
       "      <th>time_zone</th>\n",
       "      <th>duration</th>\n",
       "      <th>forward</th>\n",
       "      <th>zero_call_flg</th>\n",
       "      <th>source_b</th>\n",
       "      <th>source_f</th>\n",
       "      <th>num_b_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67596082</td>\n",
       "      <td>43588153</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67596082</td>\n",
       "      <td>82184937</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67596082</td>\n",
       "      <td>48927355</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67596082</td>\n",
       "      <td>10241386</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>67596082</td>\n",
       "      <td>229405</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id_a      id_b  time_zone  duration  forward  zero_call_flg  source_b  \\\n",
       "0  67596082  43588153          3         0        0              3         0   \n",
       "1  67596082  82184937          3         0        0              5         0   \n",
       "2  67596082  48927355          0         0        0              5         0   \n",
       "3  67596082  10241386          3         0        0              0         0   \n",
       "4  67596082    229405          0         0        1              5         1   \n",
       "\n",
       "   source_f  num_b_length  \n",
       "0         1            10  \n",
       "1         1            10  \n",
       "2         1            10  \n",
       "3         1            10  \n",
       "4         0            10  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f05098da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4.0\n",
       "1    4.0\n",
       "2    4.0\n",
       "3    4.0\n",
       "4    4.0\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b74a2243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:48:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"num_classes\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=5, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints='()', n_estimators=1000,\n",
       "              n_jobs=0, num_classes=5, num_parallel_tree=1,\n",
       "              objective='multi:softmax', predictor='auto', random_state=0, ...)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "61d95b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "eb674d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x_train, y_train, \n",
    "                                                    train_size=0.67, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f596a65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "825720     4.0\n",
       "2315181    4.0\n",
       "2278142    4.0\n",
       "882916     4.0\n",
       "1664989    4.0\n",
       "          ... \n",
       "1430734    4.0\n",
       "2511916    1.0\n",
       "2204090    4.0\n",
       "1782379    4.0\n",
       "1171125    4.0\n",
       "Name: target, Length: 924105, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ce0f82bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "50ca4acb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9953912163661056"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "206f3a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import fbeta_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c7b76570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9619194674779369"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fbeta_score(y_pred, y_test,average = 'macro', beta = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0349e42f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=5, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints='()', n_estimators=1000,\n",
       "              n_jobs=0, num_classes=5, num_parallel_tree=1,\n",
       "              objective='multi:softmax', predictor='auto', random_state=0, ...)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "67654dea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "make_scorer(fbeta_score, beta=0.5)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "ftwo_scorer = make_scorer(fbeta_score, beta=0.5)\n",
    "ftwo_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b0cac05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "111c4491",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'n_estimators': range(50, 151, 50),\n",
    "}\n",
    "\n",
    "\n",
    "estimator = xgb.XGBClassifier(max_depth=5,\n",
    "    tree_method='gpu_hist',\n",
    "    gpu_id = -1,\n",
    "    objective='multi:softmax',\n",
    "    nthread=4,\n",
    "    seed=42,\n",
    "    num_classes=5\n",
    ")\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=estimator,\n",
    "    param_grid=parameters,\n",
    "    scoring = ftwo_scorer,\n",
    "    cv = 5,\n",
    "    verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "46cd8569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[05:31:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"num_classes\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:696: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 687, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 199, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true,\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 242, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred,\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1195, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(y_true, y_pred,\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1464, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1294, in _check_set_wise_labels\n",
      "    raise ValueError(\"Target is %s but average='binary'. Please \"\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:31:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"num_classes\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:696: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 687, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 199, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true,\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 242, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred,\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1195, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(y_true, y_pred,\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1464, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1294, in _check_set_wise_labels\n",
      "    raise ValueError(\"Target is %s but average='binary'. Please \"\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:32:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"num_classes\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:696: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 687, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 199, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true,\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 242, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred,\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1195, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(y_true, y_pred,\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1464, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1294, in _check_set_wise_labels\n",
      "    raise ValueError(\"Target is %s but average='binary'. Please \"\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:32:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"num_classes\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:696: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 687, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 199, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true,\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 242, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred,\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1195, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(y_true, y_pred,\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1464, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1294, in _check_set_wise_labels\n",
      "    raise ValueError(\"Target is %s but average='binary'. Please \"\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:32:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"num_classes\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:696: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 687, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 199, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true,\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 242, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred,\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1195, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(y_true, y_pred,\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1464, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1294, in _check_set_wise_labels\n",
      "    raise ValueError(\"Target is %s but average='binary'. Please \"\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:32:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"num_classes\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:696: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 687, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 199, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true,\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 242, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred,\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1195, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(y_true, y_pred,\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1464, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1294, in _check_set_wise_labels\n",
      "    raise ValueError(\"Target is %s but average='binary'. Please \"\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:32:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"num_classes\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:696: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 687, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 199, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true,\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 242, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred,\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1195, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(y_true, y_pred,\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1464, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1294, in _check_set_wise_labels\n",
      "    raise ValueError(\"Target is %s but average='binary'. Please \"\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:32:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"num_classes\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:696: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 687, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 199, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true,\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 242, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred,\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1195, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(y_true, y_pred,\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1464, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1294, in _check_set_wise_labels\n",
      "    raise ValueError(\"Target is %s but average='binary'. Please \"\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:33:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"num_classes\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:696: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 687, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 199, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true,\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 242, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred,\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1195, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(y_true, y_pred,\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1464, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1294, in _check_set_wise_labels\n",
      "    raise ValueError(\"Target is %s but average='binary'. Please \"\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:33:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"num_classes\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:696: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 687, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 199, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true,\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 242, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred,\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1195, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(y_true, y_pred,\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1464, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1294, in _check_set_wise_labels\n",
      "    raise ValueError(\"Target is %s but average='binary'. Please \"\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:33:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"num_classes\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:696: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 687, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 199, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true,\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 242, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred,\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1195, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(y_true, y_pred,\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1464, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1294, in _check_set_wise_labels\n",
      "    raise ValueError(\"Target is %s but average='binary'. Please \"\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:33:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"num_classes\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:696: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 687, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 199, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true,\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 242, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred,\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1195, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(y_true, y_pred,\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1464, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1294, in _check_set_wise_labels\n",
      "    raise ValueError(\"Target is %s but average='binary'. Please \"\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:33:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"num_classes\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:696: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 687, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 199, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true,\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 242, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred,\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1195, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(y_true, y_pred,\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1464, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1294, in _check_set_wise_labels\n",
      "    raise ValueError(\"Target is %s but average='binary'. Please \"\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:34:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"num_classes\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:696: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 687, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 199, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true,\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 242, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred,\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1195, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(y_true, y_pred,\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1464, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1294, in _check_set_wise_labels\n",
      "    raise ValueError(\"Target is %s but average='binary'. Please \"\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:34:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"num_classes\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:696: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 687, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 199, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true,\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 242, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred,\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1195, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(y_true, y_pred,\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1464, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1294, in _check_set_wise_labels\n",
      "    raise ValueError(\"Target is %s but average='binary'. Please \"\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py:922: UserWarning: One or more of the test scores are non-finite: [nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:34:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"num_classes\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     gamma=None, gpu_id=-1, grow_policy=None,\n",
       "                                     importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_bin=None,\n",
       "                                     max_cat_to_onehot=None,\n",
       "                                     max_delta_step=None, max_depth=5,\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None, nthread=4,\n",
       "                                     num_classes=5, num_parallel_tree=None,\n",
       "                                     objective='multi:softmax', predictor=None, ...),\n",
       "             param_grid={'n_estimators': range(50, 151, 50)},\n",
       "             scoring=make_scorer(fbeta_score, beta=0.5), verbose=True)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3cd9a7e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "make_scorer(fbeta_score, beta=0.5)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "ftwo_scorer = make_scorer(fbeta_score, beta=0.5)\n",
    "ftwo_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1fb25c33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 50}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e96e3c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = xgb.XGBClassifier(max_depth=5, objective='multi:softmax', n_estimators=125, \n",
    "                        num_classes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "71d7d8ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:51:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"num_classes\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=5, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints='()', n_estimators=150,\n",
       "              n_jobs=0, num_classes=5, num_parallel_tree=1,\n",
       "              objective='multi:softmax', predictor='auto', random_state=0, ...)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5ee66a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "daa1c0b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9261447473335412"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fbeta_score(y_test, y_pred,average = 'macro', beta = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b4f5cd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = xgb.XGBClassifier(\n",
    "    max_depth=5, \n",
    "    objective='multi:softmax',\n",
    "    n_estimators=100, \n",
    "    num_classes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f5cee090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06:17:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"num_classes\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=5, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints='()', n_estimators=100,\n",
       "              n_jobs=0, num_classes=5, num_parallel_tree=1,\n",
       "              objective='multi:softmax', predictor='auto', random_state=0, ...)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "86d926cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e6a7970c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9040204365866323"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fbeta_score(y_test, y_pred,average = 'macro', beta = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "88fe34f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_GPU = xgb.XGBClassifier(\n",
    "    tree_method='gpu_hist',\n",
    "    gpu_id = -1,\n",
    "    max_depth=5, \n",
    "    objective='multi:softmax',\n",
    "    n_estimators=100, \n",
    "    num_classes=5,\n",
    "    random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ac148783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06:37:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"num_classes\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=5, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints='()', n_estimators=100,\n",
       "              n_jobs=0, num_classes=5, num_parallel_tree=1,\n",
       "              objective='multi:softmax', predictor='auto', random_state=42, ...)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_GPU.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "36841f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf_GPU.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "704b0615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8071651807715602"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fbeta_score(y_test, y_pred,average = 'macro', beta = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "67fdc073",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_GPU_2 = xgb.XGBClassifier(\n",
    "    tree_method='gpu_hist',\n",
    "    gpu_id = -1,\n",
    "    max_depth=5, \n",
    "    objective='multi:softmax',\n",
    "    n_estimators=50, \n",
    "    num_classes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "93f79d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06:32:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"num_classes\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=5, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints='()', n_estimators=50, n_jobs=0,\n",
       "              num_classes=5, num_parallel_tree=1, objective='multi:softmax',\n",
       "              predictor='auto', random_state=0, ...)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_GPU_2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b3d3d9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf_GPU_2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "66b923dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7853381902481299"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fbeta_score(y_test, y_pred,average = 'macro', beta = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185daf08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
